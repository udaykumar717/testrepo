{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**EE769 Introduction to Machine Learning**\n",
        "\n",
        "#Assignment 1: Gradient Descent, Linear Regression, and Regularization\n",
        "\n",
        "\n",
        "**Template and Instructions**\n",
        "\n",
        "\n",
        "\n",
        "1. Up to two people can team up, but only one should submit, and both should understand the entire code.\n",
        "2. Every line of code should end in a comment explaining the line\n",
        "3. It is recommended to solve the assignment in Google Colab.\n",
        "Write your roll no.s separated by commas here: 213170007\n",
        "4. Write your names here: G R Uday Kumar Reddy\n",
        "5. There are two parts to the assignment. In the Part 1, the code format has to be strictly followed to enable auto-grading. In the second part, you can be creative.\n",
        "6. **You can discuss with other groups or refer to the internet without being penalized, but you cannot copy their code and modify it. Write every line of code and comment on your own.**\n",
        "\n"
      ],
      "metadata": {
        "id": "Vl8EigX3osrA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "2c8d558bf9a7a47ea4bf343fa6fe9efb",
          "grade": false,
          "grade_id": "Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "pyC6rfqZokyx"
      },
      "source": [
        "#**Part 1 begins ...**\n",
        "**Instructions to be strictly followed:**\n",
        "\n",
        "1. Do not add any code cells or markdown cells until the end of this part. Especially, do not change the blocks that say \"TEST CASES, DO NOT CHANGE\"\n",
        "2. In all other cells only add code where it says \"CODE HERE\".\n",
        "3. If you encounter any raise NotImplementedError() calls you may comment them out.\n",
        "\n",
        "We cannot ensure correct grading if you change anything else, and you may be penalised for not following these instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Statements"
      ],
      "metadata": {
        "id": "Fuh-16Vfrtp7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fe70877a859ee0a10e9d591778022f8a",
          "grade": false,
          "grade_id": "Import_Statements",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "wGY8PStloky3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e36a214573fc40f26b45e72215d61375",
          "grade": false,
          "grade_id": "Normalize_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "y3pISCproky5"
      },
      "source": [
        "## Normalize function \n",
        "\n",
        "Add your code in the cell below to normalize the independent variables, making them zero mean and unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0039f4480dfc6d62a548d976991c3a44",
          "grade": false,
          "grade_id": "Normalize_Function",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "rS3upFWtoky5"
      },
      "outputs": [],
      "source": [
        "def Normalize(X): # Output should be a normalized data matrix of the same dimension\n",
        "    '''\n",
        "    Normalize all columns of X using mean and standard deviation\n",
        "    '''\n",
        "    return (X-X.mean(axis=0))/(X.std(axis=0)) #Along rows is Axis=1 and along columns axis=0\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7797dd606a68f028c945acd08850d108",
          "grade": true,
          "grade_id": "Normalize_Test",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "ygO-K7bzoky6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - 1 dimensional array'''\n",
        "#X=np.array([[1,2,3],[3,4,5],[7,8,9]])\n",
        "X1=np.array([1,2,3])\n",
        "np.testing.assert_array_almost_equal(Normalize(X1),np.array([-1.224,  0.      ,  1.224]),decimal=3)\n",
        "''' case 2 - 2 dimensional array'''\n",
        "X2=np.array([[4,7,6],[3,8,9],[5,11,10]])\n",
        "np.testing.assert_array_almost_equal(Normalize(X2),np.array([[ 0.  , -0.980581, -1.372813],[-1.224745, -0.392232,  0.392232],[ 1.224745,  1.372813,  0.980581]]))\n",
        "''' case 3 - 1 dimensional array with float'''\n",
        "X3=np.array([5.5,6.7,3.2,6.7])\n",
        "np.testing.assert_array_almost_equal(Normalize(X3),np.array([-0.017,  0.822, -1.627,  0.822]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccow4yKXoky7"
      },
      "source": [
        "## Prediction Function\n",
        "\n",
        "Given X and w, compute the predicted output. Do not forget to add 1's in X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7b715eb6b4f2b77697550a46e173159a",
          "grade": false,
          "grade_id": "Prediction",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3PRnu4F1oky7"
      },
      "outputs": [],
      "source": [
        "def Prediction (X, w): # Output should be a prediction vector y\n",
        "    '''\n",
        "    Compute Prediction given an input datamatrix X and weight vecor w. Output y = [X 1]w where 1 is a vector of all 1s \n",
        "    '''\n",
        "    # YOUR CODE HERE\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    return w.dot(X)\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "741f088432fb2ac3c49d3c9711d5c9c5",
          "grade": true,
          "grade_id": "PredictionTest",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "7vDdDzS4oky8"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - Known input output matrix and weights 1'''\n",
        "X1 = np.array([[3,2],[1,1]])\n",
        "w1 = np.array([2,1,1]) \n",
        "np.testing.assert_array_equal(Prediction(X1,w1),np.array([9,4]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bb888c2310846a4ec20a151ff4b44291",
          "grade": false,
          "grade_id": "cell-6fda2832d5967072",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "CE6c5oM2oky9"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "Code the four  loss functions:\n",
        "\n",
        "1. MSE loss is only for the error\n",
        "2. MAE loss is only for the error\n",
        "3. L2 loss is for MSE and L2 regularization, and can call MSE loss\n",
        "4. L1 loss is for MSE and L1 regularization, and can call MSE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "834438a2ea2e2b52359b9620e36d82b2",
          "grade": false,
          "grade_id": "MSE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Vx4oUdwRoky-"
      },
      "outputs": [],
      "source": [
        "def MSE_Loss (X, t, w, lamda =0): # Ouput should be a single number\n",
        "    '''\n",
        "    lamda=0 is a default argument to prevent errors if you pass lamda to a function that doesn't need it by mistake. \n",
        "    This allows us to call all loss functions with the same input format.\n",
        "    \n",
        "    You are encouraged read about default arguments by yourself online if you're not familiar.\n",
        "    '''\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    return (((np.square((t-y)).sum())/(N)))\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "923a1372a401b41d6ef6b0749a49ff66",
          "grade": true,
          "grade_id": "MSE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "beahjBNooky-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MSE_Loss(X,t,w),0.53,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a6bc90c02aba76b8ca4072b0b5655560",
          "grade": false,
          "grade_id": "MAE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "d6Pbd2AToky_"
      },
      "outputs": [],
      "source": [
        "def MAE_Loss (X, t, w, lamda = 0): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    return np.absolute(t-y).sum()/N\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f11d5fde7220893a9809f2954d18c5e5",
          "grade": true,
          "grade_id": "MAE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3IRXwTLwoky_"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(MAE_Loss(X,t,w),0.700,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8cbed9318984e9fb83254ad57d06436e",
          "grade": false,
          "grade_id": "L2_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "GJcMY6bPokzA"
      },
      "outputs": [],
      "source": [
        "def L2_Loss (X, t, w, lamda=0): # Output should be a single number\n",
        "    ''' Need to specify what inputs are'''\n",
        "    # YOUR CODE HERE\n",
        "    return MSE_Loss(X,t,w)+((lamda)*(np.square(w[:-1]).sum())**0.5)\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5a409056f6797cdf8cbfab61b138c37",
          "grade": true,
          "grade_id": "L2_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "DQJBvFVnokzA"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L2_Loss(X,t,w,0.5),1.675,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bb055d3436a79fb3acb7535956f57466",
          "grade": false,
          "grade_id": "L1_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "1YwydMcAokzA"
      },
      "outputs": [],
      "source": [
        "def L1_Loss (X, t, w, lamda): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    return MSE_Loss(X,t,w)+((lamda)*(np.absolute(w[:-1])).sum())\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40224dd69dd8e6499a67271c33701bf4",
          "grade": true,
          "grade_id": "L1_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "IYLTEnR5okzB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(L1_Loss(X,t,w,0.5),2.280,decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b6143269d14fa4e9b9a54a90f229620c",
          "grade": false,
          "grade_id": "NRMSE_Loss",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "GgsKvizNokzB"
      },
      "outputs": [],
      "source": [
        "def NRMSE_Metric (X, t, w): # Output should be a single number\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    return np.sqrt((((np.square((t-y)).sum())/(N))))/t.std()\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "06456562aa2ed36b11c7d40c52610133",
          "grade": true,
          "grade_id": "NRMSE_Loss_Test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "A15tcCFqokzB"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' Test case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_almost_equal(NRMSE_Metric(X,t,w),0.970,decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "32344ab855de7c731a225d416924e47d",
          "grade": false,
          "grade_id": "Gradient_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "zAJLKJNNokzC"
      },
      "source": [
        "## Gradient function\n",
        "Each Loss function will have its own gradient function:\n",
        "\n",
        "1. MSE gradient is only for the error\n",
        "2. MAE gradient is only for the error\n",
        "3. L2 gradient is for MSE and L2 regularization, and can call MSE gradient\n",
        "4. L1 gradient is for MSE and L1 regularization, and can call MSE gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c1c5a97c25a41dac499e5c245f9166b7",
          "grade": false,
          "grade_id": "MSE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "BZpqHWhBokzC"
      },
      "outputs": [],
      "source": [
        "def MSE_Gradient (X, t, w, lamda=0):\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    return -1*(t-y).dot(X.T)\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d61466927592a8776a8bfa688472bad4",
          "grade": true,
          "grade_id": "MSE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "eLjolBskokzC"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MSE_Gradient(X,t,w),np.array([2.55, 2.94, 2.9 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3d7fb24daaa75279588b80e4a10cc8c6",
          "grade": false,
          "grade_id": "MAE_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "YFF1-wxfokzD"
      },
      "outputs": [],
      "source": [
        "def MAE_Gradient (X, t, w, lamda=0): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    return (-1/N)*(np.absolute(t-y)/(t-y)).dot(X.T)\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d418bf5351112ae8716877f8bb6359",
          "grade": true,
          "grade_id": "MAE_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "1bBoPfiMokzD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(MAE_Gradient(X,t,w),np.array([0.75,  0.3 ,  0.5 , 0.]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bee96dccc2e2096ed187b41cb4e81f4e",
          "grade": false,
          "grade_id": "L2_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "qmlR91dzokzD"
      },
      "outputs": [],
      "source": [
        "def L2_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    regularization=(lamda)* (w[:-1] / ((np.square(w[:-1]).sum())**0.5))\n",
        "    regularization=np.append(regularization,0)\n",
        "    return -1*((t-y).dot(X.T)) + regularization\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f292b42c3389b24e369234a7210b87bb",
          "grade": true,
          "grade_id": "L2_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "6lxwah-zokzD"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L2_Gradient(X,t,w,0.5),np.array([2.986, 2.721, 3.009 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "5bff06a852c13effc51014992ffce310",
          "grade": false,
          "grade_id": "L1_Gradient",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "a6P-GUZ0okzE"
      },
      "outputs": [],
      "source": [
        "def L1_Gradient (X, t, w, lamda): # Output should have the same size as w\n",
        "    # YOUR CODE HERE\n",
        "    N=X.shape[0]\n",
        "    x1=np.ones((X.shape[0],1))\n",
        "    X=np.concatenate((X,x1),axis=1)\n",
        "    X=X.T\n",
        "    y=w.dot(X)\n",
        "    regularization=(lamda)*(np.absolute(w[:-1])/(w[:-1]))\n",
        "    regularization=np.append(regularization,0)\n",
        "    return -1*((t-y).dot(X.T)) + regularization\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9097b61320e470f429a9f46c7da0b219",
          "grade": true,
          "grade_id": "L1_Gradient_Test",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "dITScW5pokzE"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 '''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "w=np.array([2,-1,0.5,1])\n",
        "np.testing.assert_array_almost_equal(L1_Gradient(X,t,w,0.5),np.array([3.05, 2.44, 3.4 , 0.4 ]),decimal=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1980a2f831b5e1ddc9b510c22ef502c7",
          "grade": false,
          "grade_id": "Gradient_Desc_Title",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4ZsJWrKWokzE"
      },
      "source": [
        "## Gradient Descent Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "bba475ce42b2b792bf6e62dd34a82a98",
          "grade": false,
          "grade_id": "Gradient_Descent",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "fnlmpgxaokzF"
      },
      "outputs": [],
      "source": [
        "def Gradient_Descent (X, X_val, t, t_val, w, lamda, max_iter, epsilon, lr, lossfunc, gradfunc): # See output format in 'return' statement\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    raise NotImplementedError()\n",
        "    return w_final, train_loss_final, validation_loss_final, validation_NRMSE #You should return variables structured like this"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d10bf1b8996cb4e5d731533ab882eaa2",
          "grade": true,
          "grade_id": "Gradient_Check",
          "locked": true,
          "points": 20,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Gp-kC7iBokzF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "np.random.seed(2)\n",
        "\n",
        "X=np.array([[23,24],[1,2]])\n",
        "t=np.array([4,5])\n",
        "X_val=np.array([[3,4],[5,6]])\n",
        "t_val=np.array([3,4])\n",
        "w=np.array([3,2,1])\n",
        "results =Gradient_Descent (X, X_val, t, t_val, w, 0.1, 100, 1e-10, 1e-5, L2_Loss,L2_Gradient) \n",
        "np.testing.assert_array_almost_equal([results[1],results[2]],[697.919,17.512],decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "454ff10ef4f228e28cf5dc32b02a46b0",
          "grade": false,
          "grade_id": "PseudoInvTitle",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "M75l_wFCokzF"
      },
      "source": [
        "## Pseudo Inverse Method\n",
        "\n",
        "You have to implement a slightly more advanced version, with L2 penalty:\n",
        "\n",
        "w = (X' X + lambda I)^(-1) X' t.\n",
        "\n",
        "See, for example: Section 2 of https://web.mit.edu/zoya/www/linearRegression.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "cb4fed33ae855881d92f2d0bee916fd7",
          "grade": false,
          "grade_id": "PseudoInv",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "7ZAU-Td1okzF"
      },
      "outputs": [],
      "source": [
        "def Pseudo_Inverse (X, t, lamda): # Output should be weight vector\n",
        "    # YOUR CODE HERE\n",
        "    \n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a5178b8280650ed5d1d55dc6bbb38a29",
          "grade": true,
          "grade_id": "PseudoInvTest",
          "locked": true,
          "points": 10,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "50jkxZybokzF"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "TEST CASES, DO NOT CHANGE\n",
        "'''\n",
        "''' case 1 - other data'''\n",
        "X=np.array([[3,6,5],[4.5,6.6,6]])\n",
        "t=np.array([4,5.5])\n",
        "np.testing.assert_array_almost_equal(Pseudo_Inverse(X,t,0.5),np.array([ 0.491,  0.183,  0.319, -0.002]),decimal=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save the code above this as a RollNo1_RollNo2_1.py file after running the test blocks to make sure there are no errors."
      ],
      "metadata": {
        "id": "vwFm7JnBXDff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**... Part 1 ends**\n",
        "Below this you be more creative. Just comment out the lines where you save files (e.g. test predictions)."
      ],
      "metadata": {
        "id": "AboSSuSpw3RB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 2 begins ...**\n",
        "\n",
        "**Instructions to be loosely followed (except number 8):**\n",
        "\n",
        "1. Add more code and text cells between this and the last cell.\n",
        "2. Read training data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTrain.csv only. Do not use a local copy of the dataset.\n",
        "3. Find the best lamda for **MSE+lamda*L2(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "4. Find the best lamda for **MSE+lamda*L1(w)** loss function. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "5. Find the best lamda for the **pseudo-inv method**. Plot training and validation RMSE vs. 1/lamda (1/lamda represents model complexity). Print weights, validation RMSE, validation NMSE for the best lamda.\n",
        "6. Write your observations and conclusions.\n",
        "7. Read test data from: https://www.ee.iitb.ac.in/~asethi/Dump/TempTest.csv only. Do not use a local copy of the dataset. Predict its dependent (missing last column) using the model with the lowest MSE, RMSE, or NMSE. Save it as a file RollNo1_RollNo2_1.csv.\n",
        "8. **Disable the prediction csv file saving statement and submit this entire .ipynb file (part 1 and part 2), .py file (part 1 only), and .csv file as a single RollNo1_RollNo2_1.zip file.**\n"
      ],
      "metadata": {
        "id": "wNxr2zopT59T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**... Part 2 ends.**\n",
        "\n",
        "1. Write the name or roll no.s of friends from outside your group with whom you discussed the assignment here (no penalty for mere discussion without copying code): \n",
        "2. Write the links of sources on the internet referred here (no penalty for mere consultation without copying code): "
      ],
      "metadata": {
        "id": "X5xoNrdBYCGc"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Assignment_1_Instructions_and_Template_uday.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}